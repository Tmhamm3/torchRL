[Trainer]
session_goal = 'train'
session_tracker = 'episodic'
max_training_steps = 500000
max_episodes = 1000
seed=0
save_agent=True
load_agent=False
save_agent_folder = '/Saved_Agents/PPO-MountainCar2'
save_agent_file_name = 'PPO-Test'
load_agent_file_name='PPO-Test'
learning_rate_adjustments = [0.0005]  #optional

[Environment]
collection = 'Gym'
environment_name = 'MountainCarContinuous-v0'
render=False
evaluation_threshold = 90 #optional
lr_thresholds = [50]        #optional
eval_threshold_episodes = 100    #optional
lr_threshold_episodes = 25 #optional


[TrainingAgent]
type = 'PPO_Continuous'
update_steps = 2048   #not currently used. may be put back in
update_episodes = 2
optimizer = 'Adam'
loss_function = 'MSELoss'
minibatch_size = 64
epochs = 10
gradient_clip = 0.5
learning_rate = 0.003
gamma = 0.99
advantage_lambda = 0.99
entropy_beta = 0.001
epsilon_clip = 0.2
cdf_penalty = True
normalized_reward = False

[MemoryBuffer]
type = 'SAMemoryBuffer'
max_size = 1000000

[Mu]
layer_type = 'Linear'
network_type = 'Sequential'
layer_sizes = [64,64]
activation_functions = ['Tanh', 'Tanh']
output_function = 'Tanh'

[Critic]
layer_type = 'Linear'
network_type = 'Sequential'
layer_sizes = [64,64]
activation_functions = ['ReLU', 'ReLU']
output_function = None